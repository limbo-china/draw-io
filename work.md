## 2018-01-26

- 在国家中心distJM程序的基础上，直接add RoamData并直接执行rabbitTask，将两个漫游号码的位置更正。（8618840067805离开贵州，进入辽宁  8615328790800离开西藏进入四川）

- 修改distJM程序，原来只对加密数据的msisdn进行解密输出，现在已修改为对imsi,imei,msisdn进行解密并输出。先运行一段时间，预计之后将接入的数据加入list表中，恢复业务逻辑，将数据全部解密，并与其它省份一起同步至国家中心。

- 发现四川的三台dist机器没有数据接入


## 2018-02-05

- 山东辽宁试点需要解密历史轨迹数据，在10.233.73.3\ 10.245.73.3上配置了解密环境，将traceload和load程序改成解密版本(TraceDataLoadJM\ DataLoadHTTPJM)

- 做了测试，发现解密环境配置有问题，已经联系人员进行处理

## 2018-02-06

- 重启辽宁山东(10.233.78.2 10.245.73.15)4\5个redis实例，并接入新的加密数据，缓存文件保存在/opt/redisdumpJM 
- 解密版本loadJM和traceloadJM已经正常运行在辽宁、山东，正在入库
- 了解到10.213.73.4上的dist和traceDisp中可在log文件夹下，统计各省是否发数据，方便维护
- 明天准备对所有服务器进行维护检查


## 2018-02-07

- 对所有服务器进行了检查，226 228 两省重新接入cdr数据

## 2018-02-24

- 中心dist程序出现问题，春节期间漫游跨省数据量大。机器处理速度跟不上，线程池积压，导致入检索库的task抢不到线程。
已经给入检索库的task单独开了一个新的线程池，目前正常入库。 程序在原有DataDispatchJM的基础上修改（因山东辽宁试点已经在load处进行了解密，所以中心dist程序不再需要解密），原有jar包dist.jar更名为dist_o.jar，新程序jar包则为dist.jar

## 2018-02-27

- 228 235 240 的程序出现故障，已经恢复
- 213.4上的dist程序日志产生太多，已把[DEBUG]相关日志省略
- 在国家中心神通库中做查询，在'ReadFile'Java项目中加入Md5crypt类，可对字符串进行md5加密。

## 2018-03-02

- 在国家中心历史轨迹库的查询完成，在本地java项目ReadFile中做的查询。文件分为20个，对应各手机号码段。结果存放于d;/workplace/ReadFile/18-03-02中，分为md5加密和非加密。四个字段，若干大于1G的文件，总大小10G左右。并已同步至目标机器10.2.9.151(%$%GLZXUDPS)目录/home/iie/tracedata下。

## 2018-03-14

- 统计1.1-3.8的每天在京手机号码。1.24-3.8的数据从北京神通库中导出互不相同的手机号(group by)，原结果文件中有部分非手机号，进行了脏数据筛除。1-1-1.23的数据从hive中导出，同样将进行脏数据筛除。北京hive库，10.224.82.60，脚本等文件在/home/iie/nbw/下

- 三个漫游号码的位置更正。（均为离开西藏进入四川，18783796025，15583051360，18048006402）

- 一个重点号码的轨迹监测。3.6-3.13的7天轨迹数据导出，以及每天7天发送过去24小时的48个点的位置信息（每半小时一个点）。实现方式为利用Pyhton脚本(shishi.py)查询国家中心的实时位置接口，将结果写入文件中，以早上7时为分界点区分写入文件的名称，再用另一个脚本(scp.py)，每天定时7点将昨天的结果文件发送到xac共享机(10.2.0.102 m:111111)/home/iie/trace目录下。脚本等文件在10.213.73.3/home/iie/httptest/nbw下

## 2018-03-15

- 对1.1-3.8的北京轨迹数据进行筛除。

- hj加入2000W新号码，与原来已有的1000多W号码一起配置到新redis中，再退回到给hj推送半小时抽样数据。TraceDataLoadHJ，具体逻辑见hj&xac图
